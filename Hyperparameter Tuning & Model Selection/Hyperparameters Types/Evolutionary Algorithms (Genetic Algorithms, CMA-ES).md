
---

# üß¨ Evolutionary Algorithms in Machine Learning & Deep Learning

**Evolutionary Algorithms (EAs)** are optimization methods inspired by natural evolution. They're valuable when solving:

* Complex or non-differentiable problems
* Multimodal optimization problems (many local optima)
* Cases where gradient-based methods struggle

**Main applications in ML/DL:**

* üîß Hyperparameter Optimization
* üèõÔ∏è Neural Architecture Search (NAS)
* üß† Direct Weight Optimization (Neuroevolution)
* üìä Feature Selection

**Two popular evolutionary algorithms:**

* **Genetic Algorithms (GAs)**
* **Covariance Matrix Adaptation Evolution Strategy (CMA-ES)**

---

## ‚öôÔ∏è 1. Genetic Algorithms (GAs)

### ‚úÖ What Are Genetic Algorithms?

Genetic Algorithms work by evolving a **population** of candidate solutions using mechanisms inspired by biology:

* **Selection** (choosing the best individuals)
* **Crossover** (combining solutions)
* **Mutation** (adding randomness)

Goal: **Maximize a fitness function** (e.g., model accuracy).

---

### üìê Mathematical Foundation

* **Population:**

  $$
  P = \{\theta_1, \theta_2, \dots, \theta_N\}
  $$

  Where each \$\theta\_i\$ represents a solution (e.g., model parameters).

* **Fitness Function:**

  $$
  f(\theta_i) = \text{Performance of model using } \theta_i
  $$

* **Selection Methods:**

  * *Roulette Wheel Selection:*

    $$
    P(\theta_i) = \frac{f(\theta_i)}{\sum f(\theta_j)}
    $$

  * *Tournament Selection*

* **Crossover:**
  Combine two "parents" to create new "offspring."

* **Mutation:**
  Add small random noise:

  $$
  \theta_i' = \theta_i + \epsilon \quad\text{where}\quad \epsilon \sim \mathcal{N}(0, \sigma^2)
  $$

---

### üîÑ Genetic Algorithm Workflow

1. Initialize random population.
2. Evaluate fitness of all individuals.
3. Select parents based on fitness.
4. Apply crossover to create new solutions.
5. Mutate some offspring randomly.
6. Replace weaker individuals.
7. Repeat until stopping condition is met.

---

### üìä Benefits of GAs

* Global optimization ability (less likely to get stuck in local minima)
* Can handle discrete and continuous search spaces
* Robust and flexible
* Highly parallelizable

### ‚ö†Ô∏è Limitations of GAs

* Computationally expensive (due to population-based evaluation)
* Sensitive to hyperparameters (mutation rate, crossover rate, population size)
* May converge slowly

---

## üõ†Ô∏è Example: Python Implementation (Hyperparameter Tuning)

Below is an example of **hyperparameter optimization** for a Random Forest using **DEAP**, a popular evolutionary computation library.

```python
import random
from deap import base, creator, tools, algorithms
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score, train_test_split

# Load dataset
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define Fitness Function
def evaluate(individual):
    model = RandomForestClassifier(
        n_estimators=int(individual[0]),
        max_depth=None if individual[1] == 0 else int(individual[1]),
        min_samples_split=int(individual[2]),
        random_state=42
    )
    return cross_val_score(model, X_train, y_train, cv=5).mean(),

# Setup GA using DEAP
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)
toolbox = base.Toolbox()
toolbox.register("attr_n_estimators", random.randint, 50, 200)
toolbox.register("attr_max_depth", random.randint, 0, 30)
toolbox.register("attr_min_samples_split", random.randint, 2, 10)
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.attr_n_estimators, toolbox.attr_max_depth, toolbox.attr_min_samples_split), n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", evaluate)
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutUniformInt, low=[50, 0, 2], up=[200, 30, 10], indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the Genetic Algorithm
population = toolbox.population(n=20)
NGEN = 10
for gen in range(NGEN):
    offspring = algorithms.varAnd(population, toolbox, cxpb=0.7, mutpb=0.2)
    fits = list(map(toolbox.evaluate, offspring))
    for ind, fit in zip(offspring, fits):
        ind.fitness.values = fit
    population = toolbox.select(offspring, k=len(population))

best = tools.selBest(population, k=1)[0]
print('Best Individual:', best)
```

---


## ‚öôÔ∏è 2. Covariance Matrix Adaptation Evolution Strategy (CMA-ES)

### ‚úÖ Definition

**CMA-ES** is an advanced evolutionary strategy that adapts the covariance matrix of a multivariate Gaussian distribution to guide the sampling of new candidate solutions.

---

### üìê Mathematical Foundation

* Search distribution:

  $$
  \theta \sim \mathcal{N}(\mu, \sigma^2 C)
  $$

  * $\mu$: Mean vector (center of search).
  * $\sigma$: Global step-size.
  * $C$: Covariance matrix (shape of the search distribution).

* Update Strategy:

  * After evaluating samples, update $\mu$ towards the weighted mean of the best candidates.
  * Adapt $C$ based on the distribution of successful steps.

---

### üîÑ Process

1. Initialize $\mu$, $\sigma$, $C$.
2. Sample candidate solutions:

   
   $ \theta_i \sim \mathcal{N}(\mu, \sigma^2 C) $
3. Evaluate candidates.
4. Update:

   * $\mu$: Move towards best samples.
   * $C$: Update to reflect successful search directions.
   * $\sigma$: Adjust step size for convergence control.
5. Repeat.

---

### üìä Advantages

* Self-adaptive, minimal parameter tuning.
* Efficient in high-dimensional, continuous spaces.
* Fast convergence due to covariance adaptation.

### ‚ö†Ô∏è Disadvantages

* Only suitable for continuous parameter spaces.
* More memory intensive due to covariance matrix.
* Less effective for discrete/categorical parameters.

---

### üìä Comparison: GA vs CMA-ES

| Feature              | Genetic Algorithms (GA)       | CMA-ES                            |
| -------------------- | ----------------------------- | --------------------------------- |
| Parameter Space      | Mixed (discrete + continuous) | Continuous only                   |
| Exploration Strategy | Population-based + crossover  | Multivariate Gaussian sampling    |
| Covariance Learning  | No                            | Yes                               |
| Adaptation           | Random mutation               | Adaptive covariance and step-size |
| Parallelization      | Easy                          | Easy                              |
| Convergence Speed    | Slower                        | Faster in continuous spaces       |

---

### üõ†Ô∏è Example Python Code (CMA-ES for Simple Function Optimization)

Using the `cma` library:

```python
import cma
import numpy as np

# Objective function (to minimize)
def objective(x):
    return np.sum(np.square(x))  # Simple Sphere function

# CMA-ES optimization
es = cma.CMAEvolutionStrategy([0.5] * 10, 0.5)  # 10-dimensional problem

while not es.stop():
    solutions = es.ask()
    es.tell(solutions, [objective(x) for x in solutions])
    es.logger.add()

print('Best Solution:', es.best.x)
print('Best Fitness:', es.best.f)
```

---



* Hansen, N. (2006). "The CMA Evolution Strategy: A Tutorial."
* Goldberg, D. E. (1989). "Genetic Algorithms in Search, Optimization, and Machine Learning."
* DEAP Python Library: [https://deap.readthedocs.io/](https://deap.readthedocs.io/)
* CMA-ES Python Library: [https://github.com/CMA-ES/pycma](https://github.com/CMA-ES/pycma)

---

## 3. Covariance Matrix Adaptation Evolution Strategy (CMA-ES)

### üìñ Definition

**CMA-ES** is an advanced Evolutionary Algorithm designed for continuous parameter spaces. It samples candidate solutions from a multivariate Gaussian distribution and adapts both the distribution‚Äôs **mean** and **covariance matrix** to concentrate on promising areas of the search space.

---

### üìê Mathematical Foundation

- **Population Sampling**:  
  Sample $\lambda$ individuals from a multivariate Gaussian:

  $ \theta_i \sim \mathcal{N}(\mu, \sigma^2 \Sigma), \quad i = 1, \dots, \lambda $

- **Fitness Evaluation**:  
  Evaluate each $\theta_i$ using a fitness function $f(\theta_i)$ (e.g., accuracy or loss).

- **Update Rules**:
  - **Mean Update**:  
    $ \mu_{t+1} = \mu_t + c_m \sum_{i=1}^\mu w_i (\theta_{i,\text{best}} - \mu_t) $

  - **Covariance Matrix Update**:  
    $ \Sigma_{t+1} = (1 - c_\Sigma) \Sigma_t + c_\Sigma \sum_{i=1}^\mu w_i (\theta_{i,\text{best}} - \mu_t)(\theta_{i,\text{best}} - \mu_t)^T $

  - **Step Size Update**:  
    $ \sigma_{t+1} = \sigma_t \exp\left(\frac{c_\sigma}{d_\sigma} (p_\sigma - \hat{p}_\sigma)\right) $

---

### ‚öôÔ∏è Process

1. Initialize $\mu$, $\Sigma$, and $\sigma$.
2. Sample $\lambda$ individuals from $ \mathcal{N}(\mu, \sigma^2 \Sigma) $.
3. Evaluate fitness for each individual.
4. Select the top $\mu$ individuals.
5. Update $\mu$, $\Sigma$, and $\sigma$.
6. Repeat until convergence or budget exhaustion.
7. Output the best solution $\theta^*$.

---

### ‚úÖ Advantages

- Sample-efficient due to adaptive distribution updates.
- Effective in continuous parameter spaces.
- Robust to noise and multimodal functions.
- Self-adaptive mechanism.

---

### ‚ùå Disadvantages

- Limited to continuous parameters.
- Covariance updates can be computationally heavy in high dimensions.
- Possible premature convergence in complex landscapes.
- Complex implementation compared to basic algorithms.

---

### üìä Use Cases

- Hyperparameter optimization (e.g., learning rate, regularization strength).
- Optimizing neural network weights.
- Continuous neural architecture search.
- Policy optimization in reinforcement learning.

---

### üõ†Ô∏è Example Code

```python
import cma
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score, train_test_split

# Load dataset
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fitness function
def objective(params):
    learning_rate_init = 10 ** params[0]
    hidden_layer_size = int(np.clip(params[1], 10, 100))
    alpha = 10 ** params[2]
    
    model = MLPClassifier(
        hidden_layer_sizes=(hidden_layer_size,),
        learning_rate_init=learning_rate_init,
        alpha=alpha,
        max_iter=1000,
        random_state=42
    )
    
    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()
    return -score  # Minimizing negative accuracy

# Initialize CMA-ES
initial_params = [np.log10(0.01), 50, np.log10(0.001)]
es = cma.CMAEvolutionStrategy(initial_params, sigma0=0.5, inopts={'popsize': 10})

# Optimize
es.optimize(objective, iterations=10)

# Best parameters
best_params = es.result[0]
best_score = -es.result[1]
best_params_dict = {
    'learning_rate_init': 10 ** best_params[0],
    'hidden_layer_size': int(np.clip(best_params[1], 10, 100)),
    'alpha': 10 ** best_params[2]
}
print("Best Parameters:", best_params_dict)
print("Best Cross-Validation Score:", best_score)

# Final evaluation
best_model = MLPClassifier(
    hidden_layer_sizes=(best_params_dict['hidden_layer_size'],),
    learning_rate_init=best_params_dict['learning_rate_init'],
    alpha=best_params_dict['alpha'],
    max_iter=1000,
    random_state=42
)
best_model.fit(X_train, y_train)
test_score = best_model.score(X_test, y_test)
print("Test Set Score:", test_score)

