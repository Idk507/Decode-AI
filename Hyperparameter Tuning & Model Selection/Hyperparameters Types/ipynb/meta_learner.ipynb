{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ac5743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.53.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer,BertModel\n",
    "print(\"Transformers version:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81865a",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e72196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data Preparation\n",
    "class FewshotDataset(Dataset):\n",
    "    def __init__(self,data_path,n_way=5, k_shot=5,q_queries=5,max_len=50,tokenizer=None):\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.q_queries = q_queries\n",
    "        self.max_len = max_len\n",
    "\n",
    "        with open(data_path) as f:\n",
    "            self.raw_data = json.load(f)\n",
    "        self.classes = list(self.raw_data.keys())\n",
    "        self.tokenizer = tokenizer if tokenizer else BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.processed_data = {}\n",
    "        for cls in self.classes : \n",
    "            encoded = self.tokenizer(\n",
    "                self.raw_data[cls],\n",
    "                padding='max_length',\n",
    "                max_length=max_len,\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.processed_data[cls] = {\n",
    "                'input_ids' : encoded['input_ids'],\n",
    "                'attention_mask' : encoded['attention_mask'],\n",
    "            }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.classes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        selected_classes = random.sample(self.classes, self.n_way)\n",
    "        support_input_ids = []\n",
    "        support_attention_mask = []\n",
    "        support_labels = []\n",
    "        query_input_ids = []\n",
    "        query_attention_mask = []\n",
    "        query_labels = []\n",
    "\n",
    "        for cls_idx, cls in enumerate(selected_classes):\n",
    "            all_input_ids = self.processed_data[cls]['input_ids']\n",
    "            all_attention_mask = self.processed_data[cls]['attention_mask']\n",
    "\n",
    "            # Check if we have enough samples\n",
    "            num_samples = len(all_input_ids)\n",
    "            total_needed = self.k_shot + self.q_queries\n",
    "            \n",
    "            if num_samples < total_needed:\n",
    "                # Sample with replacement if not enough samples\n",
    "                selected = torch.randint(0, num_samples, (total_needed,))\n",
    "            else:\n",
    "                # Sample without replacement\n",
    "                selected = torch.randperm(num_samples)[:total_needed]\n",
    "\n",
    "            # Support examples \n",
    "            support_input_ids.append(all_input_ids[selected[:self.k_shot]])\n",
    "            support_attention_mask.append(all_attention_mask[selected[:self.k_shot]])\n",
    "            support_labels.extend([cls_idx] * self.k_shot)\n",
    "\n",
    "            # Query examples\n",
    "            query_input_ids.append(all_input_ids[selected[self.k_shot:]])\n",
    "            query_attention_mask.append(all_attention_mask[selected[self.k_shot:]])\n",
    "            query_labels.extend([cls_idx] * self.q_queries)\n",
    "        \n",
    "        # Stack the tensors\n",
    "        support_input_ids = torch.cat(support_input_ids)\n",
    "        support_attention_mask = torch.cat(support_attention_mask)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "\n",
    "        query_input_ids = torch.cat(query_input_ids)\n",
    "        query_attention_mask = torch.cat(query_attention_mask)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "\n",
    "        return {\n",
    "            'support_input_ids': support_input_ids,\n",
    "            'support_attention_mask': support_attention_mask,\n",
    "            'support_labels': support_labels,\n",
    "            'query_input_ids': query_input_ids,\n",
    "            'query_attention_mask': query_attention_mask,\n",
    "            'query_labels': query_labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d91f6",
   "metadata": {},
   "source": [
    "# model architecture ( prototypical network with BERT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92965d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, bert_model = 'bert-base-uncased', hidden_size = 768):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #freeze BERT parameters \n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask = attention_mask)\n",
    "        return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    def compute_prototypes(self, support_embeddings, support_labels):\n",
    "        prototypes = []\n",
    "        # Convert labels to 1D tensor\n",
    "        support_labels = support_labels.view(-1)\n",
    "        # Ensure support_embeddings is 2D (batch_size * n_way * k_shot, hidden_size)\n",
    "        support_embeddings = support_embeddings.view(-1, support_embeddings.size(-1))\n",
    "        \n",
    "        for cls in torch.unique(support_labels):\n",
    "            mask = (support_labels == cls).nonzero(as_tuple=True)[0]\n",
    "            class_embeddings = support_embeddings[mask]\n",
    "            prototype = class_embeddings.mean(dim=0)\n",
    "            prototypes.append(prototype)\n",
    "        return torch.stack(prototypes)\n",
    "\n",
    "    def compute_distances(self, prototypes, query_embeddings):\n",
    "        n_way = prototypes.shape[0]\n",
    "        n_queries = query_embeddings.shape[0]\n",
    "        # Expand prototypes and query_embeddings to compute distances\n",
    "        prototypes = prototypes.unsqueeze(0).expand(n_queries, -1, -1)\n",
    "        query_embeddings = query_embeddings.unsqueeze(1).expand(-1, n_way, -1)\n",
    "        distances = torch.sum((query_embeddings - prototypes) ** 2, dim=-1) \n",
    "        return -distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d5448",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcca39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Process\n",
    "def train_meta_learner(data_path, epochs = 10, batch_size=1, n_ways=5, k_shot=5, q_queries=5, use_gpu=True):\n",
    "    dataset = FewshotDataset(data_path=data_path, n_way=n_ways, k_shot=k_shot, q_queries=q_queries)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize model, optimizer\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = ProtoNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Add gradient clipping\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0 \n",
    "        total_samples = 0 \n",
    "\n",
    "        for batch_idx, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
    "            support_input_ids = batch['support_input_ids'].to(device)\n",
    "            support_attention_mask = batch['support_attention_mask'].to(device)\n",
    "            support_labels = batch['support_labels'].to(device)\n",
    "            query_input_ids = batch['query_input_ids'].to(device)\n",
    "            query_attention_mask = batch['query_attention_mask'].to(device)\n",
    "            query_labels = batch['query_labels'].to(device)\n",
    "\n",
    "            # Clear GPU cache if using CUDA\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            batch_loss = 0\n",
    "            batch_correct = 0\n",
    "\n",
    "            # Process each episode in the batch separately\n",
    "            for i in range(batch_size):\n",
    "                # Extract single episode data\n",
    "                episode_support_input_ids = support_input_ids[i]\n",
    "                episode_support_attention_mask = support_attention_mask[i]\n",
    "                episode_support_labels = support_labels[i]\n",
    "                episode_query_input_ids = query_input_ids[i]\n",
    "                episode_query_attention_mask = query_attention_mask[i]\n",
    "                episode_query_labels = query_labels[i]\n",
    "\n",
    "                # Get support embeddings for this episode\n",
    "                support_embeddings = model(\n",
    "                    input_ids=episode_support_input_ids,\n",
    "                    attention_mask=episode_support_attention_mask\n",
    "                )\n",
    "\n",
    "                # Get query embeddings for this episode\n",
    "                query_embeddings = model(\n",
    "                    input_ids=episode_query_input_ids,\n",
    "                    attention_mask=episode_query_attention_mask\n",
    "                )\n",
    "\n",
    "                # Compute prototypes for this episode\n",
    "                prototypes = model.compute_prototypes(\n",
    "                    support_embeddings,\n",
    "                    episode_support_labels\n",
    "                )\n",
    "\n",
    "                # Compute distances for query  \n",
    "                logits = model.compute_distances(\n",
    "                    prototypes,\n",
    "                    query_embeddings\n",
    "                )\n",
    "                \n",
    "                loss = criterion(logits, episode_query_labels)\n",
    "                batch_loss += loss \n",
    "\n",
    "                # Calculate accuracy \n",
    "                pred = torch.argmax(logits, dim=1)\n",
    "                batch_correct += (pred == episode_query_labels).sum().item() \n",
    "\n",
    "            # Average the loss and backpropagate\n",
    "            loss = batch_loss / batch_size\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Apply gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate stats \n",
    "            total_loss += loss.item()\n",
    "            total_correct += batch_correct\n",
    "            total_samples += batch_size * (n_ways * q_queries)\n",
    "\n",
    "            # Clear some memory\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_accuracy = total_correct / total_samples\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')\n",
    "        print(f'Total Samples: {total_samples}, Total Correct: {total_correct}')\n",
    "        print(f'Total Loss: {total_loss:.4f}')\n",
    "        print() \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651eaba",
   "metadata": {},
   "source": [
    "# real time inference system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc75660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_support_set(self, new_texts, new_labels):\n",
    "    # Tokenize\n",
    "    encoded = self.tokenizer(\n",
    "        new_texts, padding='max_length',\n",
    "        max_length=self.max_len, truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Ensure all new labels are added to current_classes\n",
    "    if self.current_classes is None:\n",
    "        self.current_classes = []\n",
    "    for label in new_labels:\n",
    "        if label not in self.current_classes:\n",
    "            self.current_classes.append(label)\n",
    "\n",
    "    # Convert labels to indices\n",
    "    label_indices = [self.current_classes.index(label) for label in new_labels]\n",
    "    label_tensor = torch.tensor(label_indices)\n",
    "\n",
    "    # Update support set\n",
    "    if self.support_input_ids is None:\n",
    "        self.support_input_ids = encoded['input_ids'].to(self.device)\n",
    "        self.support_attention_mask = encoded['attention_mask'].to(self.device)\n",
    "        self.support_labels = label_tensor.to(self.device)\n",
    "    else:\n",
    "        self.support_input_ids = torch.cat([\n",
    "            self.support_input_ids, encoded['input_ids'].to(self.device)\n",
    "        ])\n",
    "        self.support_attention_mask = torch.cat([\n",
    "            self.support_attention_mask, encoded['attention_mask'].to(self.device)\n",
    "        ])\n",
    "        self.support_labels = torch.cat([\n",
    "            self.support_labels, label_tensor.to(self.device)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c95c72",
   "metadata": {},
   "source": [
    "# example usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a163b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {\n",
    "    \"greeting\": [\"hello\", \"hi there\", \"good morning\", \"hey\", \"howdy\", \"greetings\", \"hello there\", \"hi\", \"good day\", \"morning\", \"afternoon\", \"evening\"],\n",
    "    \"goodbye\": [\"bye\", \"see you later\", \"goodbye\", \"farewell\", \"take care\", \"see ya\", \"later\", \"bye bye\", \"good night\", \"until next time\", \"catch you later\", \"peace out\"],\n",
    "    \"question\": [\"what's up?\", \"how are you?\", \"what's new?\", \"how's it going?\", \"how are things?\", \"what's happening?\", \"how's life?\", \"what's going on?\", \"how have you been?\", \"what's the news?\", \"how are you doing?\", \"what's the story?\"],\n",
    "    \"purchase\": [\"I want to buy\", \"I'd like to purchase\", \"can I get\", \"I need to order\", \"I want to order\", \"can I buy\", \"I'd like to get\", \"I need to purchase\", \"I want to get\", \"can I order\", \"I'd like to buy\", \"I need to get\"],\n",
    "    \"complaint\": [\"this is broken\", \"I'm not happy\", \"this doesn't work\", \"poor quality\", \"this is defective\", \"I'm disappointed\", \"this is faulty\", \"not satisfied\", \"this is damaged\", \"terrible service\", \"bad product\", \"doesn't function\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d5791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('intent_data.json', 'w') as f:\n",
    "    json.dump(example_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caad29de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training meta-learner...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(\"Training meta-learner...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436edc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 5/5 [00:17<00:00,  3.50s/it]\n",
      "Epoch 1/5: 100%|██████████| 5/5 [00:17<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 3.1480, Accuracy: 0.8160\n",
      "Total Samples: 125, Total Correct: 102\n",
      "Total Loss: 15.7402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 5/5 [00:17<00:00,  3.49s/it]\n",
      "Epoch 2/5: 100%|██████████| 5/5 [00:17<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.2951, Accuracy: 0.9600\n",
      "Total Samples: 125, Total Correct: 120\n",
      "Total Loss: 1.4753\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 5/5 [00:15<00:00,  3.09s/it]\n",
      "Epoch 3/5: 100%|██████████| 5/5 [00:15<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.3175, Accuracy: 0.9760\n",
      "Total Samples: 125, Total Correct: 122\n",
      "Total Loss: 1.5876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 5/5 [00:15<00:00,  3.05s/it]\n",
      "Epoch 4/5: 100%|██████████| 5/5 [00:15<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.0258, Accuracy: 0.9920\n",
      "Total Samples: 125, Total Correct: 124\n",
      "Total Loss: 0.1289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 5/5 [00:17<00:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.0013, Accuracy: 1.0000\n",
      "Total Samples: 125, Total Correct: 125\n",
      "Total Loss: 0.0063\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try GPU first, fall back to CPU if memory issues persist\n",
    "try:\n",
    "    model = train_meta_learner('intent_data.json', epochs=5, batch_size=1, use_gpu=True)\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e):\n",
    "        print(\"GPU out of memory, falling back to CPU...\")\n",
    "        model = train_meta_learner('intent_data.json', epochs=5, batch_size=1, use_gpu=False)\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca4481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize real-time classifier\n",
    "classifier = RealTimeFewShotClassifier(model, tokenizer)  # FIXED: Class name typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be6ce262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REAL-TIME FEW-SHOT CLASSIFIER DEMO\n",
      "============================================================\n",
      "\n",
      "1. Setting up initial support set...\n",
      "Current classes: ['goodbye', 'greeting', 'question']\n",
      "Support set size: 9 examples\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"REAL-TIME FEW-SHOT CLASSIFIER DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Initialize with some basic support examples\n",
    "print(\"\\n1. Setting up initial support set...\")\n",
    "initial_texts = [\n",
    "    \"hello there\", \"good morning\", \"hi\",  # greeting\n",
    "    \"goodbye\", \"see you later\", \"bye\",    # goodbye  \n",
    "    \"how are you?\", \"what's up?\", \"how's it going?\"  # question\n",
    "]\n",
    "initial_labels = [\"greeting\", \"greeting\", \"greeting\", \n",
    "                 \"goodbye\", \"goodbye\", \"goodbye\",\n",
    "                 \"question\", \"question\", \"question\"]\n",
    "\n",
    "classifier.update_support_set(initial_texts, initial_labels)\n",
    "print(f\"Current classes: {classifier.current_classes}\")\n",
    "print(f\"Support set size: {len(classifier.support_labels)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fd5eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Testing initial predictions...\n",
      "Query: 'hey there friend' -> Predicted: greeting (Confidence: 1.000)\n",
      "Query: 'see ya later' -> Predicted: goodbye (Confidence: 1.000)\n",
      "Query: 'what's happening today?' -> Predicted: question (Confidence: 1.000)\n",
      "Query: 'good evening' -> Predicted: greeting (Confidence: 1.000)\n",
      "Query: 'hey there friend' -> Predicted: greeting (Confidence: 1.000)\n",
      "Query: 'see ya later' -> Predicted: goodbye (Confidence: 1.000)\n",
      "Query: 'what's happening today?' -> Predicted: question (Confidence: 1.000)\n",
      "Query: 'good evening' -> Predicted: greeting (Confidence: 1.000)\n"
     ]
    }
   ],
   "source": [
    "# 2. Test initial predictions\n",
    "print(\"\\n2. Testing initial predictions...\")\n",
    "test_queries = [\n",
    "    \"hey there friend\",\n",
    "    \"see ya later\", \n",
    "    \"what's happening today?\",\n",
    "    \"good evening\"\n",
    "]\n",
    "predictions = classifier.predict(test_queries)\n",
    "predictions_with_probs, probs = classifier.predict(test_queries, return_probs=True)\n",
    "\n",
    "for i, (query, pred) in enumerate(zip(test_queries, predictions)):\n",
    "    confidence = probs[i].max()\n",
    "    print(f\"Query: '{query}' -> Predicted: {pred} (Confidence: {confidence:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0678ed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Adding new class 'complaint' with examples...\n",
      "Updated classes: ['goodbye', 'greeting', 'question', 'complaint']\n",
      "New support set size: 14 examples\n"
     ]
    }
   ],
   "source": [
    "# 3. Add a completely new class dynamically\n",
    "print(\"\\n3. Adding new class 'complaint' with examples...\")\n",
    "complaint_examples = [\n",
    "    \"this product is broken\",\n",
    "    \"I'm not satisfied with the service\", \n",
    "    \"this doesn't work properly\",\n",
    "    \"poor quality item\",\n",
    "    \"I want to return this\"\n",
    "]\n",
    "\n",
    "classifier.add_new_class(\"complaint\", complaint_examples)\n",
    "print(f\"Updated classes: {classifier.current_classes}\")\n",
    "print(f\"New support set size: {len(classifier.support_labels)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "664211e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Testing with new class included...\n",
      "Query: 'hello everyone'\n",
      "  -> Predicted: greeting (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(1.14958495e-29), 'greeting': np.float32(1.0), 'question': np.float32(0.0), 'complaint': np.float32(2.587118e-11)}\n",
      "\n",
      "Query: 'this is terrible quality'\n",
      "  -> Predicted: complaint (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.0), 'greeting': np.float32(3.605713e-24), 'question': np.float32(0.0), 'complaint': np.float32(1.0)}\n",
      "\n",
      "Query: 'farewell my friend'\n",
      "  -> Predicted: greeting (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.9999968), 'greeting': np.float32(3.2066764e-06), 'question': np.float32(0.0), 'complaint': np.float32(1.8438376e-12)}\n",
      "\n",
      "Query: 'how have you been?'\n",
      "  -> Predicted: question (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.0), 'greeting': np.float32(0.0), 'question': np.float32(1.0), 'complaint': np.float32(0.0)}\n",
      "\n",
      "Query: 'this product is defective'\n",
      "  -> Predicted: complaint (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.0), 'greeting': np.float32(3.209757e-22), 'question': np.float32(0.0), 'complaint': np.float32(1.0)}\n",
      "\n",
      "Query: 'hello everyone'\n",
      "  -> Predicted: greeting (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(1.14958495e-29), 'greeting': np.float32(1.0), 'question': np.float32(0.0), 'complaint': np.float32(2.587118e-11)}\n",
      "\n",
      "Query: 'this is terrible quality'\n",
      "  -> Predicted: complaint (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.0), 'greeting': np.float32(3.605713e-24), 'question': np.float32(0.0), 'complaint': np.float32(1.0)}\n",
      "\n",
      "Query: 'farewell my friend'\n",
      "  -> Predicted: greeting (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.9999968), 'greeting': np.float32(3.2066764e-06), 'question': np.float32(0.0), 'complaint': np.float32(1.8438376e-12)}\n",
      "\n",
      "Query: 'how have you been?'\n",
      "  -> Predicted: question (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.0), 'greeting': np.float32(0.0), 'question': np.float32(1.0), 'complaint': np.float32(0.0)}\n",
      "\n",
      "Query: 'this product is defective'\n",
      "  -> Predicted: complaint (Confidence: 1.000)\n",
      "  -> Full distribution: {'goodbye': np.float32(0.0), 'greeting': np.float32(3.209757e-22), 'question': np.float32(0.0), 'complaint': np.float32(1.0)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #4. Test with the new class\n",
    "print(\"\\n4. Testing with new class included...\")\n",
    "new_test_queries = [\n",
    "    \"hello everyone\",           # should be greeting\n",
    "    \"this is terrible quality\", # should be complaint  \n",
    "    \"farewell my friend\",       # should be goodbye\n",
    "    \"how have you been?\",       # should be question\n",
    "    \"this product is defective\" # should be complaint\n",
    "]\n",
    "\n",
    "predictions = classifier.predict(new_test_queries)\n",
    "predictions_with_probs, probs = classifier.predict(new_test_queries, return_probs=True)\n",
    "\n",
    "for i, (query, pred) in enumerate(zip(new_test_queries, predictions)):\n",
    "    confidence = probs[i].max()\n",
    "    prob_dist = {classifier.current_classes[j]: probs[i][j] for j in range(len(classifier.current_classes))}\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"  -> Predicted: {pred} (Confidence: {confidence:.3f})\")\n",
    "    print(f\"  -> Full distribution: {prob_dist}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71751eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Adding more examples to existing classes...\n",
      "Final support set size: 19 examples\n"
     ]
    }
   ],
   "source": [
    "# 5. Incrementally add more examples to existing classes\n",
    "print(\"5. Adding more examples to existing classes...\")\n",
    "more_greetings = [\"good afternoon\", \"howdy partner\", \"greetings\"]\n",
    "more_questions = [\"what's new with you?\", \"how are things going?\"]\n",
    "\n",
    "classifier.update_support_set(more_greetings, [\"greeting\"] * len(more_greetings))\n",
    "classifier.update_support_set(more_questions, [\"question\"] * len(more_questions))\n",
    "\n",
    "print(f\"Final support set size: {len(classifier.support_labels)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99a66cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Adding 'purchase' class...\n"
     ]
    }
   ],
   "source": [
    "# 6. Add another new class - purchase intent\n",
    "print(\"\\n6. Adding 'purchase' class...\")\n",
    "purchase_examples = [\n",
    "    \"I want to buy this item\",\n",
    "    \"can I purchase this product\", \n",
    "    \"I'd like to order something\",\n",
    "    \"add this to my cart\",\n",
    "    \"I need to get this\"\n",
    "]\n",
    "\n",
    "classifier.add_new_class(\"purchase\", purchase_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1f3cec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Final comprehensive test with all classes...\n",
      "Final classes: ['goodbye', 'greeting', 'question', 'complaint', 'purchase']\n",
      "Total support examples: 24\n",
      "\n",
      "Prediction Results:\n",
      "--------------------------------------------------\n",
      "Query: 'good day to you'\n",
      "  Top prediction: greeting (1.000)\n",
      "  Second choice: purchase (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'until we meet again'\n",
      "  Top prediction: goodbye (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'what's your opinion?'\n",
      "  Top prediction: question (1.000)\n",
      "  Second choice: purchase (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'this is absolutely horrible'\n",
      "  Top prediction: complaint (1.000)\n",
      "  Second choice: purchase (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'I want to buy three of these'\n",
      "  Top prediction: purchase (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'hey how's everything?'\n",
      "  Top prediction: question (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'this service is amazing'\n",
      "  Top prediction: complaint (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Final classes: ['goodbye', 'greeting', 'question', 'complaint', 'purchase']\n",
      "Total support examples: 24\n",
      "\n",
      "Prediction Results:\n",
      "--------------------------------------------------\n",
      "Query: 'good day to you'\n",
      "  Top prediction: greeting (1.000)\n",
      "  Second choice: purchase (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'until we meet again'\n",
      "  Top prediction: goodbye (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'what's your opinion?'\n",
      "  Top prediction: question (1.000)\n",
      "  Second choice: purchase (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'this is absolutely horrible'\n",
      "  Top prediction: complaint (1.000)\n",
      "  Second choice: purchase (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'I want to buy three of these'\n",
      "  Top prediction: purchase (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'hey how's everything?'\n",
      "  Top prediction: question (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n",
      "Query: 'this service is amazing'\n",
      "  Top prediction: complaint (1.000)\n",
      "  Second choice: greeting (0.000)\n",
      "  Status: HIGH CONFIDENCE ✓\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Final comprehensive test\n",
    "print(\"\\n7. Final comprehensive test with all classes...\")\n",
    "final_test_queries = [\n",
    "    \"good day to you\",              # greeting\n",
    "    \"until we meet again\",          # goodbye  \n",
    "    \"what's your opinion?\",         # question\n",
    "    \"this is absolutely horrible\",  # complaint\n",
    "    \"I want to buy three of these\", # purchase\n",
    "    \"hey how's everything?\",        # question/greeting - test ambiguous case\n",
    "    \"this service is amazing\",      # might be tricky - not clearly any class\n",
    "]\n",
    "\n",
    "predictions = classifier.predict(final_test_queries)\n",
    "predictions_with_probs, probs = classifier.predict(final_test_queries, return_probs=True)\n",
    "\n",
    "print(f\"Final classes: {classifier.current_classes}\")\n",
    "print(f\"Total support examples: {len(classifier.support_labels)}\")\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (query, pred) in enumerate(zip(final_test_queries, predictions)):\n",
    "    confidence = probs[i].max()\n",
    "    # Get top 2 predictions\n",
    "    top2_indices = probs[i].argsort()[-2:][::-1]\n",
    "    top2_classes = [classifier.current_classes[idx] for idx in top2_indices]\n",
    "    top2_probs = [probs[i][idx] for idx in top2_indices]\n",
    "    \n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"  Top prediction: {pred} ({confidence:.3f})\")\n",
    "    print(f\"  Second choice: {top2_classes[1]} ({top2_probs[1]:.3f})\")\n",
    "    \n",
    "    # Show if prediction is confident or uncertain\n",
    "    if confidence > 0.7:\n",
    "        print(f\"  Status: HIGH CONFIDENCE ✓\")\n",
    "    elif confidence > 0.5:\n",
    "        print(f\"  Status: MODERATE CONFIDENCE ~\") \n",
    "    else:\n",
    "        print(f\"  Status: LOW CONFIDENCE ⚠\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84981e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. Testing error handling...\n",
      "Caught expected error: Class greeting already exists in the support set.\n"
     ]
    }
   ],
   "source": [
    "# 8. Demonstrate error handling\n",
    "print(\"8. Testing error handling...\")\n",
    "try:\n",
    "    # Try to add duplicate class\n",
    "    classifier.add_new_class(\"greeting\", [\"hello again\"])\n",
    "except ValueError as e:\n",
    "    print(f\"Caught expected error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90a6b349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. Current classifier state summary:\n",
      "========================================\n",
      "Total classes: 5\n",
      "Classes: ['goodbye', 'greeting', 'question', 'complaint', 'purchase']\n",
      "Total support examples: 24\n",
      "\n",
      "Examples per class:\n",
      "  greeting: 6 examples\n",
      "  goodbye: 3 examples\n",
      "  question: 5 examples\n",
      "  complaint: 5 examples\n",
      "  purchase: 5 examples\n",
      "\n",
      "============================================================\n",
      "DEMO COMPLETE - Classifier ready for real-time use!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 9. Show current state summary\n",
    "print(\"\\n9. Current classifier state summary:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total classes: {len(classifier.current_classes)}\")\n",
    "print(f\"Classes: {classifier.current_classes}\")\n",
    "print(f\"Total support examples: {len(classifier.support_labels)}\")\n",
    "\n",
    "# Count examples per class\n",
    "from collections import Counter\n",
    "label_counts = Counter(classifier.support_labels.cpu().numpy())\n",
    "print(\"\\nExamples per class:\")\n",
    "for class_idx, count in label_counts.items():\n",
    "    class_name = classifier.current_classes[class_idx]\n",
    "    print(f\"  {class_name}: {count} examples\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEMO COMPLETE - Classifier ready for real-time use!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2131ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10. Interactive prediction examples:\n",
      "Input: 'I need help with something'\n",
      "Prediction: purchase (confidence: 0.989)\n",
      "All probabilities: {'goodbye': np.float32(0.0), 'greeting': np.float32(2.230397e-09), 'question': np.float32(0.0), 'complaint': np.float32(0.010685488), 'purchase': np.float32(0.98931444)}\n",
      "\n",
      "Input: 'I need help with something'\n",
      "Prediction: purchase (confidence: 0.989)\n",
      "All probabilities: {'goodbye': np.float32(0.0), 'greeting': np.float32(2.230397e-09), 'question': np.float32(0.0), 'complaint': np.float32(0.010685488), 'purchase': np.float32(0.98931444)}\n",
      "\n",
      "Input: 'thanks for your help, goodbye'\n",
      "Prediction: goodbye (confidence: 1.000)\n",
      "All probabilities: {'goodbye': np.float32(1.0), 'greeting': np.float32(6.7234066e-13), 'question': np.float32(0.0), 'complaint': np.float32(3.8552064e-26), 'purchase': np.float32(4.8823356e-17)}\n",
      "\n",
      "Input: 'thanks for your help, goodbye'\n",
      "Prediction: goodbye (confidence: 1.000)\n",
      "All probabilities: {'goodbye': np.float32(1.0), 'greeting': np.float32(6.7234066e-13), 'question': np.float32(0.0), 'complaint': np.float32(3.8552064e-26), 'purchase': np.float32(4.8823356e-17)}\n",
      "\n",
      "Input: 'this is not working at all'\n",
      "Prediction: complaint (confidence: 1.000)\n",
      "All probabilities: {'goodbye': np.float32(0.0), 'greeting': np.float32(1.4603044e-19), 'question': np.float32(0.0), 'complaint': np.float32(1.0), 'purchase': np.float32(2.8978952e-21)}\n",
      "\n",
      "Input: 'this is not working at all'\n",
      "Prediction: complaint (confidence: 1.000)\n",
      "All probabilities: {'goodbye': np.float32(0.0), 'greeting': np.float32(1.4603044e-19), 'question': np.float32(0.0), 'complaint': np.float32(1.0), 'purchase': np.float32(2.8978952e-21)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Interactive prediction function (example)\n",
    "def interactive_predict(text_input):\n",
    "    \"\"\"Helper function for real-time single predictions\"\"\"\n",
    "    prediction = classifier.predict([text_input])\n",
    "    pred_with_probs, probs = classifier.predict([text_input], return_probs=True)\n",
    "    \n",
    "    result = {\n",
    "        'input': text_input,\n",
    "        'prediction': prediction[0],\n",
    "        'confidence': probs[0].max(),\n",
    "        'all_probabilities': {classifier.current_classes[i]: probs[0][i] for i in range(len(classifier.current_classes))}\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Example of interactive usage\n",
    "print(\"\\n10. Interactive prediction examples:\")\n",
    "interactive_examples = [\n",
    "    \"I need help with something\",\n",
    "    \"thanks for your help, goodbye\",\n",
    "    \"this is not working at all\"\n",
    "]\n",
    "\n",
    "for example in interactive_examples:\n",
    "    result = interactive_predict(example)\n",
    "    print(f\"Input: '{result['input']}'\")\n",
    "    print(f\"Prediction: {result['prediction']} (confidence: {result['confidence']:.3f})\")\n",
    "    print(f\"All probabilities: {result['all_probabilities']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358881c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
