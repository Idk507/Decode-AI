{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r4BZGLpPjZdl"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function and gradient\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "def grad(x):\n",
        "    return 2 * x\n",
        "\n",
        "# Hyperparameters\n",
        "x = 4.0\n",
        "eta = 0.1\n",
        "gamma = 0.9\n",
        "epsilon = 1e-8\n",
        "Eg2 = 0  # E[g^2]_t\n",
        "n_steps = 30\n",
        "\n",
        "print(\"Step | x       | Gradient | E[g^2]   | Effective LR | Update\")\n",
        "for t in range(1, n_steps+1):\n",
        "    g = grad(x)\n",
        "    Eg2 = gamma * Eg2 + (1 - gamma) * g**2\n",
        "    lr = eta / (np.sqrt(Eg2) + epsilon)\n",
        "    update = lr * g\n",
        "    x -= update\n",
        "    print(f\"{t:>4} | {x:7.4f} | {g:8.4f} | {Eg2:8.4f} | {lr:12.6f} | {update:7.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVEvCIpbjxFd",
        "outputId": "8b28df17-83ee-4d23-ab17-5dd3e984267d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step | x       | Gradient | E[g^2]   | Effective LR | Update\n",
            "   1 |  3.6838 |   8.0000 |   6.4000 |     0.039528 |  0.3162\n",
            "   2 |  3.4635 |   7.3675 |  11.1881 |     0.029897 |  0.2203\n",
            "   3 |  3.2839 |   6.9270 |  14.8676 |     0.025935 |  0.1796\n",
            "   4 |  3.1277 |   6.5677 |  17.6943 |     0.023773 |  0.1561\n",
            "   5 |  2.9873 |   6.2554 |  19.8380 |     0.022452 |  0.1404\n",
            "   6 |  2.8582 |   5.9746 |  21.4237 |     0.021605 |  0.1291\n",
            "   7 |  2.7378 |   5.7164 |  22.5491 |     0.021059 |  0.1204\n",
            "   8 |  2.6244 |   5.4756 |  23.2924 |     0.020720 |  0.1135\n",
            "   9 |  2.5166 |   5.2487 |  23.7181 |     0.020533 |  0.1078\n",
            "  10 |  2.4136 |   5.0332 |  23.8796 |     0.020464 |  0.1030\n",
            "  11 |  2.3147 |   4.8272 |  23.8218 |     0.020489 |  0.0989\n",
            "  12 |  2.2194 |   4.6294 |  23.5827 |     0.020592 |  0.0953\n",
            "  13 |  2.1272 |   4.4387 |  23.1946 |     0.020764 |  0.0922\n",
            "  14 |  2.0379 |   4.2544 |  22.6852 |     0.020996 |  0.0893\n",
            "  15 |  1.9511 |   4.0757 |  22.0778 |     0.021282 |  0.0867\n",
            "  16 |  1.8668 |   3.9023 |  21.3928 |     0.021621 |  0.0844\n",
            "  17 |  1.7846 |   3.7335 |  20.6474 |     0.022007 |  0.0822\n",
            "  18 |  1.7045 |   3.5692 |  19.8566 |     0.022441 |  0.0801\n",
            "  19 |  1.6264 |   3.4090 |  19.0331 |     0.022922 |  0.0781\n",
            "  20 |  1.5501 |   3.2527 |  18.1878 |     0.023448 |  0.0763\n",
            "  21 |  1.4756 |   3.1002 |  17.3301 |     0.024021 |  0.0745\n",
            "  22 |  1.4029 |   2.9512 |  16.4681 |     0.024642 |  0.0727\n",
            "  23 |  1.3319 |   2.8058 |  15.6085 |     0.025312 |  0.0710\n",
            "  24 |  1.2625 |   2.6637 |  14.7572 |     0.026031 |  0.0693\n",
            "  25 |  1.1949 |   2.5251 |  13.9191 |     0.026804 |  0.0677\n",
            "  26 |  1.1288 |   2.3897 |  13.0982 |     0.027631 |  0.0660\n",
            "  27 |  1.0644 |   2.2576 |  12.2981 |     0.028515 |  0.0644\n",
            "  28 |  1.0017 |   2.1289 |  11.5215 |     0.029461 |  0.0627\n",
            "  29 |  0.9407 |   2.0034 |  10.7707 |     0.030470 |  0.0610\n",
            "  30 |  0.8813 |   1.8814 |  10.0476 |     0.031548 |  0.0594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0C3nf27kYMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Toy data\n",
        "X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
        "\n",
        "# Model\n",
        "model = nn.Linear(1, 1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.9)\n",
        "\n",
        "# Training\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB99346ZkeT6",
        "outputId": "bb0523d5-7875-42e6-ead1-cb43bd240af2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 13.0555\n",
            "Epoch 10, Loss: 9.0221\n",
            "Epoch 20, Loss: 6.9107\n",
            "Epoch 30, Loss: 5.2607\n",
            "Epoch 40, Loss: 3.9068\n",
            "Epoch 50, Loss: 2.7998\n",
            "Epoch 60, Loss: 1.9183\n",
            "Epoch 70, Loss: 1.2474\n",
            "Epoch 80, Loss: 0.7709\n",
            "Epoch 90, Loss: 0.4672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_m_vO83ke_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}