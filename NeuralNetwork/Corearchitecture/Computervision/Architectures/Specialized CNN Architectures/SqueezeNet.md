
---

## üî• What is SqueezeNet?

**SqueezeNet** (Iandola et al., 2016) is a **lightweight CNN** architecture that achieves **AlexNet-level accuracy** on ImageNet, but with **50√ó fewer parameters** (only ~1.2 million parameters vs. 60 million in AlexNet!).

**Goal:**

> Create a small, fast CNN that still performs competitively for image classification ‚Äî ideal for deployment on mobile and embedded devices.

---

## üéØ Design Philosophy

The authors focused on *model compression without accuracy loss*.
They achieved it using **three main strategies**:

1. **Replace 3√ó3 filters with 1√ó1 filters** wherever possible
   ‚Üí Fewer parameters (since 1√ó1 has 9√ó fewer weights than 3√ó3).

2. **Reduce input channels to 3√ó3 filters**
   ‚Üí Each 3√ó3 filter gets fewer input channels ‚Üí fewer total weights.

3. **Delay downsampling** (pooling)
   ‚Üí Keep large activation maps in early layers ‚Üí more spatial information preserved.

---

Input ‚Üí 1√ó1 Convs (Squeeze) ‚Üí 1√ó1 + 3√ó3 Convs (Expand) ‚Üí Concat


## üß© The Core Building Block ‚Äî The ‚ÄúFire Module‚Äù

SqueezeNet‚Äôs magic comes from the **Fire module**.

Each **Fire module** has:

* **Squeeze layer**: uses 1√ó1 filters to reduce (squeeze) the number of input channels.
* **Expand layer**: mixes 1√ó1 and 3√ó3 filters to ‚Äúexpand‚Äù features again.

```
Input
  ‚Üì
[Squeeze] 1√ó1 conv ‚Üí fewer channels
  ‚Üì
[Expand]
   ‚îú‚îÄ 1√ó1 conv (half of expansion)
   ‚îî‚îÄ 3√ó3 conv (other half)
  ‚Üì
Concatenate outputs (along channel axis)
  ‚Üì
Output
```

So a Fire module looks like this:

```
            ‚Üí 1x1 conv ‚Üí
Input ‚Üí 1x1 conv ‚Üí          ‚Üí concat ‚Üí Output
            ‚Üí 3x3 conv ‚Üí
```

---

## üî¢ Mathematical Understanding

Let‚Äôs define:

<img width="832" height="441" alt="image" src="https://github.com/user-attachments/assets/c6dea052-6da9-4e14-9b1b-14782c91f0ca" />


---

## üèóÔ∏è Full SqueezeNet Architecture

Here‚Äôs the layer-by-layer breakdown of **SqueezeNet v1.0** (the original version):

| Stage | Layer         | Type                                 | Details          |
| ----- | ------------- | ------------------------------------ | ---------------- |
| 1     | Conv1         | 7√ó7 conv, stride 2                   | 96 filters       |
|       | MaxPool1      | 3√ó3, stride 2                        |                  |
| 2     | Fire2         | Squeeze=16, Expand(1√ó1=64, 3√ó3=64)   |                  |
| 3     | Fire3         | Squeeze=16, Expand(1√ó1=64, 3√ó3=64)   |                  |
| 4     | Fire4         | Squeeze=32, Expand(1√ó1=128, 3√ó3=128) |                  |
|       | MaxPool4      | 3√ó3, stride 2                        |                  |
| 5     | Fire5         | Squeeze=32, Expand(1√ó1=128, 3√ó3=128) |                  |
| 6     | Fire6         | Squeeze=48, Expand(1√ó1=192, 3√ó3=192) |                  |
| 7     | Fire7         | Squeeze=48, Expand(1√ó1=192, 3√ó3=192) |                  |
| 8     | Fire8         | Squeeze=64, Expand(1√ó1=256, 3√ó3=256) |                  |
|       | MaxPool8      | 3√ó3, stride 2                        |                  |
| 9     | Fire9         | Squeeze=64, Expand(1√ó1=256, 3√ó3=256) |                  |
| 10    | Conv10        | 1√ó1 conv                             | #classes filters |
| 11    | GlobalAvgPool | 13√ó13 ‚Üí 1√ó1                          |                  |
| 12    | Softmax       | ‚Äî                                    | classification   |

---

## üß† Why It‚Äôs Efficient

### 1. Smaller filters

1√ó1 filters drastically reduce parameters.

### 2. Channel squeezing

Fewer input channels to 3√ó3 filters ‚Üí fewer multiplications.

### 3. Late pooling

Downsampling is postponed ‚Üí large feature maps longer ‚Üí better accuracy.

### 4. Global Average Pooling

No fully connected layers ‚Üí drastically reduces parameters.

---

## üìê Parameter Comparison

| Model           | Parameters  | Size (MB) | Accuracy (Top-1, ImageNet) |
| --------------- | ----------- | --------- | -------------------------- |
| AlexNet         | 60 million  | ~240 MB   | 57%                        |
| SqueezeNet      | 1.2 million | ~4.8 MB   | 57%                        |
| MobileNetV2     | 3.4 million | ~14 MB    | 71%                        |
| EfficientNet-B0 | 5.3 million | ~20 MB    | 77%                        |

---

## ‚öôÔ∏è PyTorch Implementation (Simple and Readable)

Let‚Äôs build the **Fire module** and the **SqueezeNet model**.

```python
# squeeznet.py
import torch
import torch.nn as nn
import torch.nn.functional as F

# ---- Fire Module ----
class Fire(nn.Module):
    def __init__(self, in_channels, squeeze_channels, expand1x1_channels, expand3x3_channels):
        super(Fire, self).__init__()
        # Squeeze layer
        self.squeeze = nn.Conv2d(in_channels, squeeze_channels, kernel_size=1)
        self.squeeze_activation = nn.ReLU(inplace=True)
        
        # Expand layers
        self.expand1x1 = nn.Conv2d(squeeze_channels, expand1x1_channels, kernel_size=1)
        self.expand3x3 = nn.Conv2d(squeeze_channels, expand3x3_channels, kernel_size=3, padding=1)
        self.expand_activation = nn.ReLU(inplace=True)
    
    def forward(self, x):
        x = self.squeeze_activation(self.squeeze(x))
        out1 = self.expand1x1(x)
        out3 = self.expand3x3(x)
        return self.expand_activation(torch.cat([out1, out3], dim=1))


# ---- SqueezeNet ----
class SqueezeNet(nn.Module):
    def __init__(self, num_classes=1000):
        super(SqueezeNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=7, stride=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
            
            Fire(96, 16, 64, 64),
            Fire(128, 16, 64, 64),
            Fire(128, 32, 128, 128),
            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
            
            Fire(256, 32, 128, 128),
            Fire(256, 48, 192, 192),
            Fire(384, 48, 192, 192),
            Fire(384, 64, 256, 256),
            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
            
            Fire(512, 64, 256, 256)
        )
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Conv2d(512, num_classes, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1))
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return torch.flatten(x, 1)
```

‚úÖ You can run this directly:

```python
model = SqueezeNet(num_classes=10)
x = torch.randn(1, 3, 224, 224)
y = model(x)
print(y.shape)   # torch.Size([1, 10])
```

---

## üßÆ Training Setup (Example)

```python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

for epoch in range(5):
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

---

## üìä Key Insights

| Concept              | Explanation                                                       |
| -------------------- | ----------------------------------------------------------------- |
| **1√ó1 Conv filters** | Drastically reduce parameters                                     |
| **Squeeze ratio**    | Number of squeeze channels / expand channels (~0.125‚Äì0.5 typical) |
| **No FC layers**     | Use global average pooling                                        |
| **ReLU everywhere**  | Simple, fast nonlinearities                                       |
| **Dropout**          | Adds regularization for small model                               |

---

## ‚öñÔ∏è SqueezeNet vs Other Compact CNNs

| Model               | Params (M) | Accuracy | Notes                        |
| ------------------- | ---------- | -------- | ---------------------------- |
| **SqueezeNet**      | 1.2        | 57%      | Smallest                     |
| **MobileNetV2**     | 3.4        | 71%      | Depthwise separable convs    |
| **ShuffleNet**      | 1.4        | 69%      | Group conv + channel shuffle |
| **EfficientNet-B0** | 5.3        | 77%      | Compound scaling             |
| **ResNet-18**       | 11.7       | 69%      | Baseline comparison          |

---

## üß† Summary

**SqueezeNet = ‚ÄúAlexNet accuracy with 50√ó fewer parameters.‚Äù**

**Core idea:** Fire modules (1√ó1 squeeze + 1√ó1 & 3√ó3 expand).
**Benefits:**

* Compact and fast.
* Easy to train from scratch.
* Excellent for edge devices (mobile, Raspberry Pi, etc.).
* Used as a backbone for lightweight detection/segmentation networks.

---

## üöÄ Extensions

* **SqueezeNet v1.1** ‚Äî smaller filters (3√ó3 instead of 7√ó7 in conv1), faster.
* **SqueezeNext** ‚Äî deeper but more efficient variant.
* **SqueezeSeg** ‚Äî SqueezeNet adapted for LiDAR point-cloud segmentation.
* **Tiny-YOLO + SqueezeNet** ‚Äî for real-time object detection.

---

## üí° TL;DR

| Concept            | Summary                                      |
| ------------------ | -------------------------------------------- |
| üß± Architecture    | Fire modules (1√ó1 squeeze + expand)          |
| ‚öôÔ∏è Parameters      | ~1.2M                                        |
| üß© Filter Strategy | Replace 3√ó3 with 1√ó1; fewer input channels   |
| üïí Speed           | ~2‚Äì3√ó faster than AlexNet                    |
| üß† Accuracy        | Similar to AlexNet (~57% on ImageNet)        |
| üì± Use case        | Lightweight classification / edge deployment |

---
